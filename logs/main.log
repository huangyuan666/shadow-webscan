DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /p.php HTTP/1.1" 404 469
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET / HTTP/1.1" 200 510
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET / HTTP/1.1" 200 510
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:80
ERROR:crawler.curl:error request url: http://127.0.0.1:80
ERROR:crawler.curl:Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
  File "D:\codes\shadow-webscan\crawler\curl.py", line 96, in wrapper
    return connect(object_, *args, **kwargs)
  File "D:\codes\shadow-webscan\crawler\curl.py", line 96, in wrapper
    return connect(object_, *args, **kwargs)
  File "D:\codes\shadow-webscan\crawler\curl.py", line 96, in wrapper
    return connect(object_, *args, **kwargs)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000000032F16A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000000032F16A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\crawler\curl.py", line 60, in __send
    **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000000032F16A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。',))

DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /OVGvnXQw.html HTTP/1.1" 404 469
DEBUG:crawler.crawler:already request size: 1, left request size: 12
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/ HTTP/1.1" 200 830
DEBUG:crawler.crawler:already request size: 2, left request size: 38
DEBUG:crawler.crawler:skip, ext is white: http://127.0.0.1:8000/bak.zip
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /index.php.bak HTTP/1.1" 200 19
DEBUG:crawler.crawler:already request size: 3, left request size: 36
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /links.html HTTP/1.1" 200 389
DEBUG:crawler.crawler:already request size: 4, left request size: 39
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): www.w3.org:80
ERROR:crawler.curl:error request url: http://www.w3.org:80/TR/html4/strict.dtd
ERROR:crawler.curl:Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
  File "D:\codes\shadow-webscan\crawler\curl.py", line 96, in wrapper
    return connect(object_, *args, **kwargs)
  File "D:\codes\shadow-webscan\crawler\curl.py", line 96, in wrapper
    return connect(object_, *args, **kwargs)
  File "D:\codes\shadow-webscan\crawler\curl.py", line 96, in wrapper
    return connect(object_, *args, **kwargs)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connection.py", line 164, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPConnection object at 0x00000000033995C0>, 'Connection to www.w3.org timed out. (connect timeout=3)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='www.w3.org', port=80): Max retries exceeded with url: /TR/html4/strict.dtd (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000000033995C0>, 'Connection to www.w3.org timed out. (connect timeout=3)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\crawler\curl.py", line 60, in __send
    **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 504, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPConnectionPool(host='www.w3.org', port=80): Max retries exceeded with url: /TR/html4/strict.dtd (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000000033995C0>, 'Connection to www.w3.org timed out. (connect timeout=3)'))

DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /index.php HTTP/1.1" 200 19
DEBUG:crawler.crawler:already request size: 5, left request size: 37
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): www.w3.org:80
ERROR:crawler.curl:error request url: http://www.w3.org:80/TR/html4/strict.dtd
ERROR:crawler.curl:Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Program Files\Python\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\crawler\curl.py", line 60, in __send
    **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/
DEBUG:crawler.crawler:skip, ext is white: http://127.0.0.1:8000/bak.zip
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/index.php
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/index.php.bak
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/links.html
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/ORIG_HEAD HTTP/1.1" 200 41
DEBUG:crawler.crawler:already request size: 6, left request size: 30
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/config HTTP/1.1" 200 354
DEBUG:crawler.crawler:already request size: 7, left request size: 29
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/logs/ HTTP/1.1" 200 385
DEBUG:crawler.crawler:already request size: 8, left request size: 33
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/index HTTP/1.1" 200 5616
DEBUG:chardet.charsetprober:SHIFT_JIS Japanese prober hit error at byte 15
DEBUG:chardet.charsetprober:EUC-JP Japanese prober hit error at byte 19
DEBUG:chardet.charsetprober:GB2312 Chinese prober hit error at byte 28
DEBUG:chardet.charsetprober:EUC-KR Korean prober hit error at byte 19
DEBUG:chardet.charsetprober:CP949 Korean prober hit error at byte 19
DEBUG:chardet.charsetprober:Big5 Chinese prober hit error at byte 25
DEBUG:chardet.charsetprober:EUC-TW Taiwan prober hit error at byte 19
DEBUG:chardet.charsetprober:windows-1251 Russian confidence = 0.05496396052095146
DEBUG:chardet.charsetprober:KOI8-R Russian confidence = 0.03326267266009304
DEBUG:chardet.charsetprober:ISO-8859-5 Russian confidence = 0.035953883170213564
DEBUG:chardet.charsetprober:MacCyrillic Russian confidence = 0.047819250392616426
DEBUG:chardet.charsetprober:IBM866 Russian confidence = 0.025985803663995874
DEBUG:chardet.charsetprober:IBM855 Russian confidence = 0.04952780134078211
DEBUG:chardet.charsetprober:ISO-8859-7 Greek confidence = 0.06250198769265497
DEBUG:chardet.charsetprober:windows-1253 Greek confidence = 0.06281860895975525
DEBUG:chardet.charsetprober:ISO-8859-5 Bulgairan confidence = 0.03383076087958641
DEBUG:chardet.charsetprober:windows-1251 Bulgarian confidence = 0.042892158346902826
DEBUG:chardet.charsetprober:TIS-620 Thai confidence = 0.042571913622900304
DEBUG:chardet.charsetprober:ISO-8859-9 Turkish confidence = 0.32693194948760457
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.0
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.042207554476057084
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.04748349878556422
DEBUG:chardet.charsetprober:windows-1251 Russian confidence = 0.05496396052095146
DEBUG:chardet.charsetprober:KOI8-R Russian confidence = 0.03326267266009304
DEBUG:chardet.charsetprober:ISO-8859-5 Russian confidence = 0.035953883170213564
DEBUG:chardet.charsetprober:MacCyrillic Russian confidence = 0.047819250392616426
DEBUG:chardet.charsetprober:IBM866 Russian confidence = 0.025985803663995874
DEBUG:chardet.charsetprober:IBM855 Russian confidence = 0.04952780134078211
DEBUG:chardet.charsetprober:ISO-8859-7 Greek confidence = 0.06250198769265497
DEBUG:chardet.charsetprober:windows-1253 Greek confidence = 0.06281860895975525
DEBUG:chardet.charsetprober:ISO-8859-5 Bulgairan confidence = 0.03383076087958641
DEBUG:chardet.charsetprober:windows-1251 Bulgarian confidence = 0.042892158346902826
DEBUG:chardet.charsetprober:TIS-620 Thai confidence = 0.042571913622900304
DEBUG:chardet.charsetprober:ISO-8859-9 Turkish confidence = 0.32693194948760457
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.0
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.042207554476057084
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.04748349878556422
DEBUG:crawler.crawler:already request size: 9, left request size: 32
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/COMMIT_EDITMSG HTTP/1.1" 200 1299
DEBUG:chardet.charsetprober:utf-8  confidence = 0.99
DEBUG:chardet.charsetprober:SHIFT_JIS Japanese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-JP Japanese confidence = 0.01
DEBUG:chardet.charsetprober:GB2312 Chinese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-KR Korean confidence = 0.01
DEBUG:chardet.charsetprober:CP949 Korean confidence = 0.01
DEBUG:chardet.charsetprober:Big5 Chinese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-TW Taiwan confidence = 0.01
DEBUG:chardet.charsetprober:windows-1251 Russian confidence = 0.01
DEBUG:chardet.charsetprober:KOI8-R Russian confidence = 0.01
DEBUG:chardet.charsetprober:ISO-8859-5 Russian confidence = 0.0
DEBUG:chardet.charsetprober:MacCyrillic Russian confidence = 0.0
DEBUG:chardet.charsetprober:IBM866 Russian confidence = 0.17722378236037348
DEBUG:chardet.charsetprober:IBM855 Russian confidence = 0.12799495392693638
DEBUG:chardet.charsetprober:ISO-8859-7 Greek confidence = 0.0
DEBUG:chardet.charsetprober:windows-1253 Greek confidence = 0.0
DEBUG:chardet.charsetprober:ISO-8859-5 Bulgairan confidence = 0.0
DEBUG:chardet.charsetprober:windows-1251 Bulgarian confidence = 0.0
DEBUG:chardet.charsetprober:TIS-620 Thai confidence = 0.06951091596153158
DEBUG:chardet.charsetprober:ISO-8859-9 Turkish confidence = 0.5158365184399751
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.0
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.0
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.0
DEBUG:chardet.charsetprober:utf-8  confidence = 0.99
DEBUG:chardet.charsetprober:SHIFT_JIS Japanese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-JP Japanese confidence = 0.01
DEBUG:chardet.charsetprober:GB2312 Chinese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-KR Korean confidence = 0.01
DEBUG:chardet.charsetprober:CP949 Korean confidence = 0.01
DEBUG:chardet.charsetprober:Big5 Chinese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-TW Taiwan confidence = 0.01
DEBUG:crawler.crawler:already request size: 10, left request size: 34
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/ HTTP/1.1" 200 1008
DEBUG:crawler.crawler:already request size: 11, left request size: 56
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/FETCH_HEAD HTTP/1.1" 200 97
DEBUG:crawler.crawler:already request size: 12, left request size: 55
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/ HTTP/1.1" 200 5012
DEBUG:crawler.crawler:already request size: 13, left request size: 357
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/HEAD HTTP/1.1" 200 23
DEBUG:crawler.crawler:already request size: 14, left request size: 356
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/packed-refs HTTP/1.1" 200 114
DEBUG:crawler.crawler:already request size: 15, left request size: 355
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/refs/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 16, left request size: 361
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/description HTTP/1.1" 200 73
DEBUG:crawler.crawler:already request size: 17, left request size: 360
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/info/ HTTP/1.1" 200 356
DEBUG:crawler.crawler:already request size: 18, left request size: 362
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): www.w3.org:80
ERROR:crawler.curl:error request url: http://www.w3.org:80/TR/html4/strict.dtd
ERROR:crawler.curl:Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Program Files\Python\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\crawler\curl.py", line 60, in __send
    **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/COMMIT_EDITMSG
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/config
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/description
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/FETCH_HEAD
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/HEAD
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/index
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/info/
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/logs/
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/objects/
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/ORIG_HEAD
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/packed-refs
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/refs/
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /index.php?a=1&b=2 HTTP/1.1" 200 19
DEBUG:crawler.crawler:already request size: 19, left request size: 347
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /index.php?a=1&c=2&d=3 HTTP/1.1" 200 19
DEBUG:crawler.crawler:already request size: 20, left request size: 346
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/index.php
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "POST /index.php HTTP/1.1" 501 497
DEBUG:crawler.crawler:already request size: 21, left request size: 345
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/logs/refs/ HTTP/1.1" 200 405
DEBUG:crawler.crawler:already request size: 22, left request size: 349
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/logs/HEAD HTTP/1.1" 200 1911
DEBUG:chardet.charsetprober:utf-8  confidence = 0.99
DEBUG:chardet.charsetprober:SHIFT_JIS Japanese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-JP Japanese confidence = 0.01
DEBUG:chardet.charsetprober:GB2312 Chinese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-KR Korean confidence = 0.01
DEBUG:chardet.charsetprober:CP949 Korean confidence = 0.01
DEBUG:chardet.charsetprober:Big5 Chinese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-TW Taiwan confidence = 0.01
DEBUG:chardet.charsetprober:windows-1251 Russian confidence = 0.01
DEBUG:chardet.charsetprober:KOI8-R Russian confidence = 0.01
DEBUG:chardet.charsetprober:ISO-8859-5 Russian confidence = 0.0
DEBUG:chardet.charsetprober:MacCyrillic Russian confidence = 0.0
DEBUG:chardet.charsetprober:IBM866 Russian confidence = 0.14480592520303806
DEBUG:chardet.charsetprober:IBM855 Russian confidence = 0.08037810395187482
DEBUG:chardet.charsetprober:ISO-8859-7 Greek confidence = 0.0
DEBUG:chardet.charsetprober:windows-1253 Greek confidence = 0.0
DEBUG:chardet.charsetprober:ISO-8859-5 Bulgairan confidence = 0.0
DEBUG:chardet.charsetprober:windows-1251 Bulgarian confidence = 0.0
DEBUG:chardet.charsetprober:TIS-620 Thai confidence = 0.10331895112790059
DEBUG:chardet.charsetprober:ISO-8859-9 Turkish confidence = 0.4044366214781109
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.0
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.0
DEBUG:chardet.charsetprober:windows-1255 Hebrew confidence = 0.0
DEBUG:chardet.charsetprober:utf-8  confidence = 0.99
DEBUG:chardet.charsetprober:SHIFT_JIS Japanese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-JP Japanese confidence = 0.01
DEBUG:chardet.charsetprober:GB2312 Chinese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-KR Korean confidence = 0.01
DEBUG:chardet.charsetprober:CP949 Korean confidence = 0.01
DEBUG:chardet.charsetprober:Big5 Chinese confidence = 0.01
DEBUG:chardet.charsetprober:EUC-TW Taiwan confidence = 0.01
DEBUG:crawler.crawler:already request size: 23, left request size: 348
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): www.w3.org:80
ERROR:crawler.curl:error request url: http://www.w3.org:80/TR/html4/strict.dtd
ERROR:crawler.curl:Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Program Files\Python\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\crawler\curl.py", line 60, in __send
    **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/logs/HEAD
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/logs/refs/
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): www.w3.org:80
ERROR:crawler.curl:error request url: http://www.w3.org:80/TR/html4/strict.dtd
ERROR:crawler.curl:Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Program Files\Python\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\crawler\curl.py", line 60, in __send
    **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

DEBUG:crawler.crawler:skip, ext is white: http://127.0.0.1:8000/bak.zip
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): www.w3.org:80
ERROR:crawler.curl:error request url: http://www.w3.org:80/TR/html4/strict.dtd
ERROR:crawler.curl:Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Program Files\Python\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\crawler\curl.py", line 60, in __send
    **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/commit-msg.sample HTTP/1.1" 200 896
DEBUG:crawler.crawler:already request size: 24, left request size: 341
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/pre-commit.sample HTTP/1.1" 200 1638
DEBUG:crawler.crawler:already request size: 25, left request size: 340
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/applypatch-msg.sample HTTP/1.1" 200 478
DEBUG:crawler.crawler:already request size: 26, left request size: 339
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/fsmonitor-watchman.sample HTTP/1.1" 200 3327
DEBUG:crawler.crawler:already request size: 27, left request size: 340
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/update.sample HTTP/1.1" 200 3610
DEBUG:crawler.crawler:already request size: 28, left request size: 339
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/post-update.sample HTTP/1.1" 200 189
DEBUG:crawler.crawler:already request size: 29, left request size: 338
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/prepare-commit-msg.sample HTTP/1.1" 200 1492
DEBUG:crawler.crawler:already request size: 30, left request size: 337
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/pre-rebase.sample HTTP/1.1" 200 4898
DEBUG:crawler.crawler:already request size: 31, left request size: 336
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/pre-push.sample HTTP/1.1" 200 1348
DEBUG:crawler.crawler:already request size: 32, left request size: 335
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/pre-applypatch.sample HTTP/1.1" 200 424
DEBUG:crawler.crawler:already request size: 33, left request size: 334
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/hooks/pre-receive.sample HTTP/1.1" 200 544
DEBUG:crawler.crawler:already request size: 34, left request size: 333
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): www.w3.org:80
ERROR:crawler.curl:error request url: http://www.w3.org:80/TR/html4/strict.dtd
ERROR:crawler.curl:Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Program Files\Python\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Program Files\Python\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\util\retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\urllib3\connectionpool.py", line 306, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\codes\shadow-webscan\crawler\curl.py", line 60, in __send
    **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\codes\shadow-webscan\venv\lib\site-packages\requests\adapters.py", line 529, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='www.w3.org', port=80): Read timed out. (read timeout=3)

DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/applypatch-msg.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/commit-msg.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/fsmonitor-watchman.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/post-update.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/pre-applypatch.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/pre-commit.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/pre-push.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/pre-rebase.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/pre-receive.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/prepare-commit-msg.sample
DEBUG:crawler.crawler:skip, request already: http://127.0.0.1:8000/.git/hooks/update.sample
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/31/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 35, left request size: 323
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/75/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 36, left request size: 327
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/1c/ HTTP/1.1" 200 632
DEBUG:crawler.crawler:already request size: 37, left request size: 333
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/1a/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 38, left request size: 335
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/a6/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 39, left request size: 339
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/c2/ HTTP/1.1" 200 632
DEBUG:crawler.crawler:already request size: 40, left request size: 345
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/d1/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 41, left request size: 347
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/9e/ HTTP/1.1" 200 632
DEBUG:crawler.crawler:already request size: 42, left request size: 353
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/40/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 43, left request size: 355
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/32/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 44, left request size: 357
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/b2/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 45, left request size: 359
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/29/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 46, left request size: 361
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/a5/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 47, left request size: 363
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/d8/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 48, left request size: 365
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/6c/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 49, left request size: 369
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/27/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 50, left request size: 373
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/6e/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 51, left request size: 375
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/e7/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 52, left request size: 377
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/e0/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 53, left request size: 379
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/b9/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 54, left request size: 381
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/cc/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 55, left request size: 383
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/64/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 56, left request size: 387
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/8e/ HTTP/1.1" 200 733
DEBUG:crawler.crawler:already request size: 57, left request size: 395
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/fa/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 58, left request size: 397
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/83/ HTTP/1.1" 200 632
DEBUG:crawler.crawler:already request size: 59, left request size: 403
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/00/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 60, left request size: 407
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/68/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 61, left request size: 411
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/d9/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 62, left request size: 413
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/03/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 63, left request size: 415
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/b6/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 64, left request size: 417
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/52/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 65, left request size: 419
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/0a/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 66, left request size: 421
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/10/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 67, left request size: 425
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/88/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 68, left request size: 429
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/f5/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 69, left request size: 431
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/17/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 70, left request size: 433
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/22/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 71, left request size: 435
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/67/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 72, left request size: 439
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/info/ HTTP/1.1" 200 333
DEBUG:crawler.crawler:already request size: 73, left request size: 439
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/ad/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 74, left request size: 441
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/7f/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 75, left request size: 443
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/2a/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 76, left request size: 445
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/3b/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 77, left request size: 447
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/b4/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 78, left request size: 451
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/4c/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 79, left request size: 453
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/8c/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 80, left request size: 455
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/b5/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 81, left request size: 457
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/f9/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 82, left request size: 461
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/3d/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 83, left request size: 463
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/8b/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 84, left request size: 465
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/d7/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 85, left request size: 467
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/e4/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 86, left request size: 471
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/4f/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 87, left request size: 475
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/ec/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 88, left request size: 479
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/0d/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 89, left request size: 483
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/84/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 90, left request size: 485
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/be/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 91, left request size: 487
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/c5/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 92, left request size: 491
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/80/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 93, left request size: 493
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/c1/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 94, left request size: 495
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/c0/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 95, left request size: 497
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/b3/ HTTP/1.1" 200 531
DEBUG:crawler.crawler:already request size: 96, left request size: 501
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/60/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 97, left request size: 503
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/c8/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 98, left request size: 505
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/e9/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 99, left request size: 507
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/fc/ HTTP/1.1" 200 430
DEBUG:crawler.crawler:already request size: 100, left request size: 509
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "GET /.git/objects/7d/ HTTP/1.1" 200 632
DEBUG:crawler.crawler:already request size: 101, left request size: 515
DEBUG:crawler.crawler:over, request count on over: 100
DEBUG:vulnerability.common.manager:plugin: sql check <Request>{'_Request__url': <'URL'>{'_URL__raw_url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__scheme': 'http', '_URL__username': None, '_URL__password': None, '_URL__hostname': '127.0.0.1', '_URL__port': 8000, '_URL__netloc': '127.0.0.1:8000', '_URL__path': '/.git/objects/00/', '_URL__parameters': '', '_URL__query': '', '_URL__fragment': '', '_URL__parsed': True, '_URL__query_string': ''}, '_Request__method': 'GET', '_Request__headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36'}, '_Request__cookies': None, '_Request__referer': None, '_Request__user_agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36', '_Request__query_string': '', '_Request__data': None}
DEBUG:vulnerability.common.manager:plugin: xss check <Request>{'_Request__url': <'URL'>{'_URL__raw_url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__scheme': 'http', '_URL__username': None, '_URL__password': None, '_URL__hostname': '127.0.0.1', '_URL__port': 8000, '_URL__netloc': '127.0.0.1:8000', '_URL__path': '/.git/objects/00/', '_URL__parameters': '', '_URL__query': '', '_URL__fragment': '', '_URL__parsed': True, '_URL__query_string': ''}, '_Request__method': 'GET', '_Request__headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36'}, '_Request__cookies': None, '_Request__referer': None, '_Request__user_agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36', '_Request__query_string': '', '_Request__data': None}
DEBUG:vulnerability.common.manager:plugin: cmd check <Request>{'_Request__url': <'URL'>{'_URL__raw_url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__scheme': 'http', '_URL__username': None, '_URL__password': None, '_URL__hostname': '127.0.0.1', '_URL__port': 8000, '_URL__netloc': '127.0.0.1:8000', '_URL__path': '/.git/objects/00/', '_URL__parameters': '', '_URL__query': '', '_URL__fragment': '', '_URL__parsed': True, '_URL__query_string': ''}, '_Request__method': 'GET', '_Request__headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36'}, '_Request__cookies': None, '_Request__referer': None, '_Request__user_agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36', '_Request__query_string': '', '_Request__data': None}
DEBUG:vulnerability.common.manager:plugin: lfi check <Request>{'_Request__url': <'URL'>{'_URL__raw_url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__scheme': 'http', '_URL__username': None, '_URL__password': None, '_URL__hostname': '127.0.0.1', '_URL__port': 8000, '_URL__netloc': '127.0.0.1:8000', '_URL__path': '/.git/objects/00/', '_URL__parameters': '', '_URL__query': '', '_URL__fragment': '', '_URL__parsed': True, '_URL__query_string': ''}, '_Request__method': 'GET', '_Request__headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36'}, '_Request__cookies': None, '_Request__referer': None, '_Request__user_agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36', '_Request__query_string': '', '_Request__data': None}
DEBUG:vulnerability.common.manager:plugin: bak check <Request>{'_Request__url': <'URL'>{'_URL__raw_url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__scheme': 'http', '_URL__username': None, '_URL__password': None, '_URL__hostname': '127.0.0.1', '_URL__port': 8000, '_URL__netloc': '127.0.0.1:8000', '_URL__path': '/.git/objects/00/', '_URL__parameters': '', '_URL__query': '', '_URL__fragment': '', '_URL__parsed': True, '_URL__query_string': ''}, '_Request__method': 'GET', '_Request__headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36'}, '_Request__cookies': None, '_Request__referer': None, '_Request__user_agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36', '_Request__query_string': '', '_Request__data': None}
DEBUG:vulnerability.common.manager:plugin: packed check <Request>{'_Request__url': <'URL'>{'_URL__raw_url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__url': 'http://127.0.0.1:8000/.git/objects/00/', '_URL__scheme': 'http', '_URL__username': None, '_URL__password': None, '_URL__hostname': '127.0.0.1', '_URL__port': 8000, '_URL__netloc': '127.0.0.1:8000', '_URL__path': '/.git/objects/00/', '_URL__parameters': '', '_URL__query': '', '_URL__fragment': '', '_URL__parsed': True, '_URL__query_string': ''}, '_Request__method': 'GET', '_Request__headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36'}, '_Request__cookies': None, '_Request__referer': None, '_Request__user_agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36', '_Request__query_string': '', '_Request__data': None}
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "HEAD /bak.zip HTTP/1.1" 200 0
DEBUG:vulnerability.common.packed:check result: http://127.0.0.1:8000/bak.zip, <'Response'>{'_Response__status_code': 200, '_Response__status_msg': 'OK', '_Response__headers': {'Server': 'SimpleHTTP/0.6 Python/3.6.7', 'Date': 'Fri, 11 Jan 2019 14:14:26 GMT', 'Content-type': 'application/x-zip-compressed', 'Content-Length': '152', 'Last-Modified': 'Fri, 11 Jan 2019 00:54:20 GMT'}, '_Response__body': '', '_Response__request_url': <'URL'>{'_URL__raw_url': 'http://127.0.0.1:8000/bak.zip', '_URL__url': 'http://127.0.0.1:8000/bak.zip', '_URL__scheme': 'http', '_URL__username': None, '_URL__password': None, '_URL__hostname': '127.0.0.1', '_URL__port': 8000, '_URL__netloc': '127.0.0.1:8000', '_URL__path': '/bak.zip', '_URL__parameters': '', '_URL__query': '', '_URL__fragment': '', '_URL__parsed': True, '_URL__query_string': ''}, '_Response__uid': '33df75a8-15ab-11e9-b1ea-00e070092db6', '_Response__charset': None}
INFO:vulnerability.common.packed:<'Vulnerability'>{'_Vulnerability__name': '压缩文件', '_Vulnerability__rank': <Serverity.HIGH: 3>, '_Vulnerability__url': 'http://127.0.0.1:8000/bak.zip', '_Vulnerability__method': 'HEAD', '_Vulnerability__key': None, '_Vulnerability__playload': None}
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "HEAD /bak.rar HTTP/1.1" 404 0
DEBUG:vulnerability.common.packed:check result: http://127.0.0.1:8000/bak.rar, <'Response'>{'_Response__status_code': 404, '_Response__status_msg': 'File not found', '_Response__headers': {'Server': 'SimpleHTTP/0.6 Python/3.6.7', 'Date': 'Fri, 11 Jan 2019 14:14:27 GMT', 'Connection': 'close', 'Content-Type': 'text/html;charset=utf-8', 'Content-Length': '469'}, '_Response__body': '', '_Response__request_url': <'URL'>{'_URL__raw_url': 'http://127.0.0.1:8000/bak.rar', '_URL__url': 'http://127.0.0.1:8000/bak.rar', '_URL__scheme': 'http', '_URL__username': None, '_URL__password': None, '_URL__hostname': '127.0.0.1', '_URL__port': 8000, '_URL__netloc': '127.0.0.1:8000', '_URL__path': '/bak.rar', '_URL__parameters': '', '_URL__query': '', '_URL__fragment': '', '_URL__parsed': True, '_URL__query_string': ''}, '_Response__uid': '347a2f1a-15ab-11e9-9311-00e070092db6', '_Response__charset': 'utf-8'}
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
DEBUG:urllib3.connectionpool:http://127.0.0.1:8000 "HEAD /bak.tar HTTP/1.1" 404 0
DEBUG:vulnerability.common.packed:check result: http://127.0.0.1:8000/bak.tar, <'Response'>{'_Response__status_code': 404, '_Response__status_msg': 'File not found', '_Response__headers': {'Server': 'SimpleHTTP/0.6 Python/3.6.7', 'Date': 'Fri, 11 Jan 2019 14:14:28 GMT', 'Connection': 'close', 'Content-Type': 'text/html;charset=utf-8', 'Content-Length': '469'}, '_Response__body': '', '_Response__request_url': <'URL'>{'_URL__raw_url': 'http://127.0.0.1:8000/bak.tar', '_URL__url': 'http://127.0.0.1:8000/bak.tar', '_URL__scheme': 'http', '_URL__username': None, '_URL__password': None, '_URL__hostname': '127.0.0.1', '_URL__port': 8000, '_URL__netloc': '127.0.0.1:8000', '_URL__path': '/bak.tar', '_URL__parameters': '', '_URL__query': '', '_URL__fragment': '', '_URL__parsed': True, '_URL__query_string': ''}, '_Response__uid': '3512872c-15ab-11e9-9e82-00e070092db6', '_Response__charset': 'utf-8'}
DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:8000
